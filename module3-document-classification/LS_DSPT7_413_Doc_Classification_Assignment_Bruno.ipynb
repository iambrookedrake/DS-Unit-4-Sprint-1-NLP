{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4087, 3) (1022, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>\\nStyle: Speyside single malt scotch Color: Walnut Aroma: Richly sherried and thick, with notes of nuts and toffee. Wood resins contribute spice and variety. Fruitcake at Christmas. Palate: Thick, chewy in texture, and quite ripe. Again the fruitcake. Very deep and mature with some underlying maltiness. Dry, spicy, oak notes fight off all that sherry and add balance and complexity. Long, soothing finish. \\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>\\nVery bright and lively, with a nice balance of flavors. Zesty fruit (lemon, peach, ripe pineapple, golden raisin) on a bed of layered sweetness (creamy vanilla, light honey, lightly toasted marshmallow, and a hint of coconut). Gently dry, delicately spicy, dried citrus finish. Light enough and with enough zing to enjoy before dinner, but it should stand up well enough after dinner, too. This is a nice whisky, but it shows a lighter, more elegant side of Glenrothes. It doesn’t express the rich, opulent notes often shown in bottlings like the 1972 Vintage, for example.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>\\nA new oloroso-forward Chivas positioned to split between the 12 and 18 year olds? I got this. Refined and inviting nose of lemon pith, black fruits, and Kola Kubes. The velvety texture is wonderfully smooth, redolent of an apricot custard Danish, lime zest, raisin, currant, mixed peel, and walnut, with a growing bitter-lemon note. Quite unique finish, like sucking on lumpy Spanish lemons speckled with spices. (LA, NY, Miami, Chicago, Northern California, but will go national)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>\\nAged in bourbon casks and then enhanced in Rioja wine casks. A mélange of red berry fruits, firm malt, thick vanilla and spicy oak, along with a hint of grape skin, anise, and orange peel. Gritty, dry finish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>\\nThere is a freshness to the wood on the nose, laced with caramel and delicate minty notes. The palate pours pleasantly chewy with molten butterscotch and offers a pleasant jolt of cinnamon and clove that suggests rye at work, before settling on bitter orange peel, salted caramel, and cocoa, leading to a drying leathery and warm spice finish. Nicely done.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  3461   \n",
       "1  2604   \n",
       "2  3341   \n",
       "3  3764   \n",
       "4  2306   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       description  \n",
       "0  \\nStyle: Speyside single malt scotch Color: Walnut Aroma: Richly sherried and thick, with notes of nuts and toffee. Wood resins contribute spice and variety. Fruitcake at Christmas. Palate: Thick, chewy in texture, and quite ripe. Again the fruitcake. Very deep and mature with some underlying maltiness. Dry, spicy, oak notes fight off all that sherry and add balance and complexity. Long, soothing finish. \\r\\n                                                                                                                                                                     \n",
       "1  \\nVery bright and lively, with a nice balance of flavors. Zesty fruit (lemon, peach, ripe pineapple, golden raisin) on a bed of layered sweetness (creamy vanilla, light honey, lightly toasted marshmallow, and a hint of coconut). Gently dry, delicately spicy, dried citrus finish. Light enough and with enough zing to enjoy before dinner, but it should stand up well enough after dinner, too. This is a nice whisky, but it shows a lighter, more elegant side of Glenrothes. It doesn’t express the rich, opulent notes often shown in bottlings like the 1972 Vintage, for example.  \n",
       "2  \\nA new oloroso-forward Chivas positioned to split between the 12 and 18 year olds? I got this. Refined and inviting nose of lemon pith, black fruits, and Kola Kubes. The velvety texture is wonderfully smooth, redolent of an apricot custard Danish, lime zest, raisin, currant, mixed peel, and walnut, with a growing bitter-lemon note. Quite unique finish, like sucking on lumpy Spanish lemons speckled with spices. (LA, NY, Miami, Chicago, Northern California, but will go national)                                                                                               \n",
       "3  \\nAged in bourbon casks and then enhanced in Rioja wine casks. A mélange of red berry fruits, firm malt, thick vanilla and spicy oak, along with a hint of grape skin, anise, and orange peel. Gritty, dry finish.                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4  \\nThere is a freshness to the wood on the nose, laced with caramel and delicate minty notes. The palate pours pleasantly chewy with molten butterscotch and offers a pleasant jolt of cinnamon and clove that suggests rye at work, before settling on bitter orange peel, salted caramel, and cocoa, leading to a drying leathery and warm spice finish. Nicely done.                                                                                                                                                                                                                           "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.704918\n",
       "0    0.279178\n",
       "2    0.015904\n",
       "Name: ratingCategory, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of ratingCategory: 0 (Excellent), 1 (Good), 2 (Poor)\n",
    "train.ratingCategory.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>4331</td>\n",
       "      <td>\\nFour years ago Glen Grant was in a sorry state, its beautiful gardens in need of some love and attention, its malts neglected and seemingly unloved. Then Campari bought it and we have heard very little more since. That’s until now. With a new visitor center, the gardens in full bloom, and the owners determined to make it a major player, things are looking up. This limited edition 170th anniversary bottling is made up of vintages stretching back to the 70s. They include a couple of sherry butts and some peated spirit. The result is a rich malt with some buttery toffee notes at first, distinctive lemon and green apple notes, and a touch of aniseed. Midway through, it sets off in a more feisty direction, with some peat, sharp spice, and green banana skin. Beguiling and unusual, it’s a statement of intent from an iconic distillery — watch this space. (Selected specialist outlets, excluding the U.S.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>4679</td>\n",
       "      <td>\\nThough the color suggests good cask activity, the initial approach shows a dram that seems slightly unfocused and youthful. There are some kernel-like cereal elements and very little smokiness, with touches of salt and oil. The feeling is that it’s only starting to blossom — and there is a floral element — and has been bottled too early. It’s all very focused, lifted, and aromatic, but when compared to the Adelphi you can’t help but wonder whether the same distillery is involved.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>4085</td>\n",
       "      <td>\\nLovely golden honey color. Lush and sweet (the Sauternes impact is obvious), with honey-drenched apricot, sultana, and lemon gum drops. Vanilla, candied nuts, and subtle botanicals round out the palate. Decent oak grip on the finish keeps the whisky from being too cloying.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "939   4331   \n",
       "628   4679   \n",
       "2622  4085   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          description  \\\n",
       "939   \\nFour years ago Glen Grant was in a sorry state, its beautiful gardens in need of some love and attention, its malts neglected and seemingly unloved. Then Campari bought it and we have heard very little more since. That’s until now. With a new visitor center, the gardens in full bloom, and the owners determined to make it a major player, things are looking up. This limited edition 170th anniversary bottling is made up of vintages stretching back to the 70s. They include a couple of sherry butts and some peated spirit. The result is a rich malt with some buttery toffee notes at first, distinctive lemon and green apple notes, and a touch of aniseed. Midway through, it sets off in a more feisty direction, with some peat, sharp spice, and green banana skin. Beguiling and unusual, it’s a statement of intent from an iconic distillery — watch this space. (Selected specialist outlets, excluding the U.S.)    \n",
       "628   \\nThough the color suggests good cask activity, the initial approach shows a dram that seems slightly unfocused and youthful. There are some kernel-like cereal elements and very little smokiness, with touches of salt and oil. The feeling is that it’s only starting to blossom — and there is a floral element — and has been bottled too early. It’s all very focused, lifted, and aromatic, but when compared to the Adelphi you can’t help but wonder whether the same distillery is involved.                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2622  \\nLovely golden honey color. Lush and sweet (the Sauternes impact is obvious), with honey-drenched apricot, sultana, and lemon gum drops. Vanilla, candied nuts, and subtle botanicals round out the palate. Decent oak grip on the finish keeps the whisky from being too cloying.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "      ratingCategory  \n",
       "939   0               \n",
       "628   0               \n",
       "2622  0               "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Excellent\" category\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "train[train.ratingCategory == 0].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>5063</td>\n",
       "      <td>\\nPort Ellen is going to just keep getting rarer and more expensive, and the quality is going to get more variable. This one shows the traditional Port Ellen characteristics (seaweed, tar, charcoal, damp earth, vanilla, salt, white pepper), but it just seems to flatten out mid-palate, leading to a fairly lifeless, slightly astringent finish. I feel like some of the guts were ripped out of this whisky. Bottling at a higher strength (and not chill-filtered) would have helped immensely.\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>5081</td>\n",
       "      <td>\\nAged for “at least” one month, this bourbon is a collaboration with the band Fierce Dead Rabbit. Better Days is pale gold and noticeably cloudy. On the nose it’s paste, yeasty bread dough, and wet pavement. On the palate it is all over the place with raw oak, cinnamon, almond, and black pepper. There's no balance and no integration. The finish is short, hot, and dry. As whiskey ages, it goes through odd, awkward phases, and that's where this one is.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>5036</td>\n",
       "      <td>\\nVery light in aroma and flavor. There are no off flavors. It’s just uninspiring. Delicate notes of vanilla custard, honey, caramel corn, sweet corn, and subtle fruit. Fleeting finish.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "2008  5063   \n",
       "1667  5081   \n",
       "2239  5036   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     description  \\\n",
       "2008  \\nPort Ellen is going to just keep getting rarer and more expensive, and the quality is going to get more variable. This one shows the traditional Port Ellen characteristics (seaweed, tar, charcoal, damp earth, vanilla, salt, white pepper), but it just seems to flatten out mid-palate, leading to a fairly lifeless, slightly astringent finish. I feel like some of the guts were ripped out of this whisky. Bottling at a higher strength (and not chill-filtered) would have helped immensely.\\n   \n",
       "1667  \\nAged for “at least” one month, this bourbon is a collaboration with the band Fierce Dead Rabbit. Better Days is pale gold and noticeably cloudy. On the nose it’s paste, yeasty bread dough, and wet pavement. On the palate it is all over the place with raw oak, cinnamon, almond, and black pepper. There's no balance and no integration. The finish is short, hot, and dry. As whiskey ages, it goes through odd, awkward phases, and that's where this one is.                                      \n",
       "2239  \\nVery light in aroma and flavor. There are no off flavors. It’s just uninspiring. Delicate notes of vanilla custard, honey, caramel corn, sweet corn, and subtle fruit. Fleeting finish.                                                                                                                                                                                                                                                                                                                    \n",
       "\n",
       "      ratingCategory  \n",
       "2008  2               \n",
       "1667  2               \n",
       "2239  2               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Poor\" category\n",
    "train[train.ratingCategory == 2].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Training Set into Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3269,) (818,) (3269,) (818,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['description'], \n",
    "                                                    train['ratingCategory'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=train['ratingCategory'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Extract the vectorizer and model from grid_search pipeline\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "svm = LinearSVC()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', svm)])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__norm', 'vect__preprocessor', 'vect__smooth_idf', 'vect__stop_words', 'vect__strip_accents', 'vect__sublinear_tf', 'vect__token_pattern', 'vect__tokenizer', 'vect__use_idf', 'vect__vocabulary', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__loss', 'clf__max_iter', 'clf__multi_class', 'clf__penalty', 'clf__random_state', 'clf__tol', 'clf__verbose'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params().keys() #check list of available parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'vect__max_df': (0.75, 1.0)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    #'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(train.description, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subNumber' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e9d81f334b34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Best to Use an Integer or Timestamp for different versions of your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'whiskey-reviews-dspt7/submission{subNumber}.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msubNumber\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subNumber' is not defined"
     ]
    }
   ],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'whiskey-reviews-dspt7/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Use parameters from GridSearch in previous section\n",
    "vect = TfidfVectorizer(stop_words='english', \n",
    "                       ngram_range=(1,2),\n",
    "                       min_df=2, \n",
    "                       max_df=0.7,\n",
    "                       max_features=20000)\n",
    "\n",
    "# Add dimensionality reduction\n",
    "svd = TruncatedSVD(algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "# # Use parameters from RandomSearch in previous section\n",
    "# clf = LinearSVC(C=0.5, \n",
    "#                 penalty='l2')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', vect),      # TF-IDF Vectorizer\n",
    "    ('svd', svd),        # Truncated SVD Dimensionality Reduction\n",
    "    ('clf', rfc)         # RandomForest Classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_df': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.7,\n",
       "                                                        max_features=20000,\n",
       "                                                        min_df=2,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        stri...\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'vect__max_df': (0.75, 1.0)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'lsa__svd__n_components': (100,250),\n",
    "    'svd__n_components': stats.randint(100, 5000),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(train.description, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iambr\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=5. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=0.7,\n",
       "                                                              max_features=20000,\n",
       "                                                              min_df=2,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words='english...\n",
       "                                                                     min_samples_leaf=1,\n",
       "                                                                     min_samples_split=2,\n",
       "                                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                                     n_estimators=100,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     oob_score=False,\n",
       "                                                                     random_state=None,\n",
       "                                                                     verbose=0,\n",
       "                                                                     warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'vect__max_df': (0.75, 1.0)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Fit\n",
    "# random_search = RandomizedSearchCV(pipe, parameters, cv=2, n_iter=5, n_jobs=-1, verbose=1)\n",
    "# random_search.fit(train.description, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "subNumber = 1\n",
    "submission.to_csv(f'./whiskey-reviews-dspt7/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.674333411879426"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6806962678772897"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995106435037925"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = grid_search.predict(train.description)\n",
    "accuracy_score(train.ratingCategory, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"NLP is awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "nlp_vector = doc.vector\n",
    "print(len(nlp_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.99885249e-01,  3.45714986e-01,  1.64885744e-02, -2.35542506e-02,\n",
       "        1.43662512e-01, -1.23924986e-02,  1.52034998e-01, -3.65224987e-01,\n",
       "        1.13594748e-01,  1.15108001e+00, -1.83196187e-01,  2.74120513e-02,\n",
       "       -1.02375746e-01,  3.13747525e-02,  4.55302559e-02, -1.85307249e-01,\n",
       "       -1.46043763e-01,  9.30569947e-01, -2.01018006e-01, -2.33615756e-01,\n",
       "        4.34175134e-03, -6.69924989e-02,  6.06357455e-02, -1.58095673e-01,\n",
       "       -9.37802419e-02,  1.93459496e-01,  1.92345500e-01, -5.94324991e-02,\n",
       "        1.68709978e-02, -1.27937496e-01,  6.42787516e-02, -3.23557481e-02,\n",
       "        1.33825943e-01,  1.85234249e-01,  6.99924976e-02,  1.28265738e-01,\n",
       "        2.38190234e-01,  1.21133000e-01, -2.19828337e-01, -2.38023698e-01,\n",
       "        1.51863992e-01, -9.34367478e-02, -1.61462426e-02,  1.24664992e-01,\n",
       "        2.68729985e-01,  3.37404758e-01, -2.72237003e-01,  2.25244984e-02,\n",
       "        5.79980016e-02, -1.66924000e-01,  1.35736749e-01,  1.77590013e-01,\n",
       "        4.06724960e-02, -1.05852522e-02,  1.97865050e-02,  1.44996002e-01,\n",
       "        1.05809495e-01,  4.19660270e-01,  3.52082513e-02, -5.71468547e-02,\n",
       "       -2.04114199e-01,  5.89075312e-03, -1.81168005e-01, -2.58040011e-01,\n",
       "        2.55802751e-01, -1.73875257e-01, -1.00634992e-01,  6.76530004e-02,\n",
       "       -1.25827163e-01, -3.32092457e-02, -1.44035012e-01, -1.34055004e-01,\n",
       "        3.05615515e-01, -8.26974958e-02,  2.37627476e-02,  7.30759576e-02,\n",
       "       -2.06165671e-01, -1.64319187e-01, -2.34690249e-01,  4.71832514e-01,\n",
       "        1.20885037e-02,  2.10295260e-01,  2.65832752e-01,  2.37935007e-01,\n",
       "        1.41107500e-01,  2.84989923e-02,  1.93976745e-01, -3.40078503e-01,\n",
       "        9.55332518e-02, -4.35159951e-02,  4.00212519e-02,  2.69119978e-01,\n",
       "       -1.89492524e-01,  8.43112469e-02, -8.08840021e-02,  5.77812530e-02,\n",
       "       -9.69072580e-02,  3.89475375e-03, -1.62849948e-03, -2.08506763e-01,\n",
       "       -3.54615003e-02, -3.52507502e-01, -2.62964994e-01, -8.40693265e-02,\n",
       "        3.44424248e-01, -1.17345005e-01,  4.05819744e-01,  1.91088498e-01,\n",
       "       -7.46175051e-02,  2.72382367e-02,  6.00731224e-02, -2.81269014e-01,\n",
       "       -2.39461511e-02, -1.56893864e-01, -4.48643751e-02,  1.02539003e-01,\n",
       "        8.86795074e-02,  8.94099921e-02, -1.01255000e-01,  1.53585020e-02,\n",
       "        7.06249475e-03,  1.55372739e-01,  9.09750015e-02, -6.97307512e-02,\n",
       "       -1.57485008e-02,  4.12250310e-03, -2.26205498e-01, -8.27734917e-02,\n",
       "        2.33408008e-02, -1.15150027e-02, -1.96931750e-01, -3.72034252e-01,\n",
       "       -2.39709988e-02, -1.14243500e-01,  1.72540009e-01, -9.44250450e-03,\n",
       "       -7.99422413e-02,  2.12847777e-02, -1.16022490e-02,  2.84724832e-02,\n",
       "       -1.47995257e+00,  2.37615004e-01,  4.53500003e-01,  1.12024993e-02,\n",
       "        2.92374939e-02, -2.07597241e-01,  3.13660473e-01, -1.16655000e-01,\n",
       "        2.69999951e-02, -2.42834985e-02, -1.50119990e-01,  2.72197276e-02,\n",
       "       -2.08722517e-01,  7.88367540e-02,  9.02534500e-02, -2.23511487e-01,\n",
       "        6.00899979e-02, -2.60680020e-01,  9.54430029e-02, -3.28124948e-02,\n",
       "        8.26175064e-02, -3.83562557e-02,  4.70334962e-02, -1.00009248e-01,\n",
       "        1.39486402e-01, -7.09575042e-02, -9.35494900e-02, -3.07654977e-01,\n",
       "       -1.83905736e-01,  6.96682483e-02,  7.63840526e-02,  9.17489976e-02,\n",
       "        9.23838466e-02,  3.78069989e-02, -2.17262506e-01,  9.66600031e-02,\n",
       "       -4.48799878e-03,  7.75095001e-02, -4.60250005e-02, -1.17242500e-01,\n",
       "        8.87600332e-03, -7.47302473e-02, -2.33194992e-01, -2.88789988e-01,\n",
       "       -7.29739964e-02, -2.33877495e-01, -2.53519982e-01,  2.83797458e-02,\n",
       "        3.74687500e-02,  1.28844261e-01, -6.32498413e-04, -2.40114987e-01,\n",
       "       -1.65877640e-02, -4.37072515e-02,  9.43669975e-02,  2.82335013e-01,\n",
       "        1.14192754e-01, -2.82066762e-01,  7.20527530e-01,  5.61274998e-02,\n",
       "       -2.92685002e-01, -2.78509796e-01,  2.03254998e-01,  9.03065056e-02,\n",
       "       -1.68933243e-01, -1.80775020e-02, -1.50980771e-01,  1.31270006e-01,\n",
       "        2.98899990e-02, -1.24563247e-01, -2.15485260e-01, -2.14411750e-01,\n",
       "        4.23329994e-02, -8.51342529e-02, -2.98512205e-02,  3.80968511e-01,\n",
       "        2.69282490e-01, -7.31247514e-02, -1.13472499e-01,  1.95384994e-02,\n",
       "       -3.01210016e-01,  1.48774236e-01, -4.19649929e-02,  7.37649947e-02,\n",
       "       -4.37124968e-02, -9.77159962e-02, -2.99232483e-01,  2.36372501e-01,\n",
       "       -1.76247850e-01,  9.80192572e-02, -2.06544995e-01, -1.87632501e-01,\n",
       "       -1.19729996e-01,  4.80115041e-02, -9.72517431e-02,  4.84865010e-02,\n",
       "       -3.94000076e-02, -8.08324963e-02, -2.53457487e-01,  2.89809965e-02,\n",
       "        1.02731243e-01, -2.80597508e-02, -8.48409981e-02, -4.62200083e-02,\n",
       "        1.86205998e-01, -3.65851760e-01, -1.87187746e-01, -7.35622570e-02,\n",
       "        1.05392501e-01,  1.31764501e-01,  9.59224999e-03, -1.62685007e-01,\n",
       "        5.22875041e-02, -1.14390947e-01, -1.88332498e-01, -6.80129975e-02,\n",
       "        1.87025070e-02, -1.15867496e-01, -5.76550029e-02, -1.93938017e-01,\n",
       "        2.56175488e-01, -1.51407957e-01, -8.30405205e-03, -2.83612497e-02,\n",
       "       -9.88190770e-02, -6.28914982e-02,  8.45902413e-02,  1.76411495e-01,\n",
       "        3.49892497e-01,  2.77740002e-01, -5.37140727e-01, -7.90382475e-02,\n",
       "       -5.03612518e-01, -2.08469242e-01, -1.43678486e-01, -8.57562423e-02,\n",
       "        5.02665006e-02, -2.25591525e-01,  2.98319995e-01,  3.61245051e-02,\n",
       "        3.35117519e-01, -1.01047501e-01, -5.80013730e-02, -2.04257499e-02,\n",
       "        1.02729246e-01, -4.56669182e-02,  1.29641756e-01,  1.00354999e-01,\n",
       "        1.30923495e-01, -2.02844739e-02,  6.48382455e-02, -6.62632510e-02,\n",
       "       -1.33743003e-01, -1.38099995e-02,  2.08575740e-01,  1.54507488e-01,\n",
       "        2.52972484e-01,  5.81384972e-02, -2.78002501e-01,  2.85645664e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(train.description)\n",
    "len(X) == len(train.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_word_vectors(test.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iambr\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(16, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995106435037925"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = grid_search.predict(train['description'])\n",
    "accuracy_score(train['ratingCategory'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv(f'./whiskey-reviews-dspt7/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
